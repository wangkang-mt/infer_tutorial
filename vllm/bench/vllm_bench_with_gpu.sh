#!/usr/bin/env bash
# ==========================================
# vLLM æ‰¹é‡æ€§èƒ½æµ‹è¯•è„šæœ¬
# ä½œè€…: kang.wang-ext
# ==========================================

set -e

show_help() {
cat << EOF
ç”¨æ³•ï¼š
  bash $0 [å‚æ•°...]

å‚æ•°åˆ—è¡¨ï¼š
  --model-path PATH        ï¼ˆå¿…å¡«ï¼‰æ¨¡å‹è·¯å¾„
  --gpu-num N              ï¼ˆå¿…å¡«ï¼‰æ¨ç†ç”¨ GPU æ•°é‡ï¼Œç”¨äºç”Ÿæˆæ—¥å¿—ç›®å½•ä»¥åŠ GPU util ç›‘æ§
  --config-file PATH      ï¼ˆå¯é€‰ï¼‰æµ‹è¯•é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤: config/vllm_bench_config.txt
  --model-name NAME        æ¨¡å‹æœåŠ¡åï¼Œç¼ºçœåˆ™è‡ªåŠ¨ä»è·¯å¾„æ¨æ–­ï¼ˆä¸åšå¤§å°å†™è½¬æ¢ï¼‰
  --dtype xxx              æ¨ç†ç²¾åº¦ï¼Œä»…ç”¨äºç”Ÿæˆæ—¥å¿—æ ‡è®°
  --port PORT              é»˜è®¤: 8000
  --host HOST              é»˜è®¤: localhost
ç¤ºä¾‹ï¼š
  bash $0 \\
    --model-path /home/dist/DeepSeek-Coder-V2-Lite-Instruct \\
    --model-name DeepSeek-Coder-V2-Lite-Instruct  \\
    --gpu-num 4 \\
    --dtype bf16

  1. 72 ~ 100 è¡Œå¯é…ç½®æµ‹è¯•å¹¶å‘æ•°ä»¥åŠè¾“å…¥è¾“å‡ºç»„åˆï¼
  2. è‡ªåŠ¨ç›‘æ§ GPU åˆ©ç”¨ç‡å¹¶åˆå¹¶è‡³ç»“æœ JSON ä¸­ã€‚
EOF
}

# ---- å¿…å¡«å‚æ•° ----
MODEL_PATH=""
MODEL_NAME=""

# ---- é»˜è®¤å‚æ•° ----
HOST="localhost"
PORT=8000
DATASET_NAME="random"
CONFIG_FILE="config/vllm_bench_config.txt"

# ---- å‚æ•°è§£æ ----
while [[ "$#" -gt 0 ]]; do
    case $1 in
        --model-path) MODEL_PATH="$2"; shift ;;
        --model-name) MODEL_NAME="$2"; shift ;;
        --gpu-num) GPU_NUM="$2"; shift ;;
        --port) PORT="$2"; shift ;;
        --host) HOST="$2"; shift ;;
        --config-file) CONFIG_FILE="$2"; shift ;;
        --help|-h) show_help; exit 0 ;;
        *) echo "æœªçŸ¥å‚æ•°: $1"; exit 1 ;;
    esac
    shift
done

# ---- æ ¡éªŒå¿…å¡«é¡¹ ----
if [[ -z "$MODEL_PATH" ]]; then
    echo "âŒ é”™è¯¯: å¿…é¡»ä¼ å…¥ --model-path å‚æ•°ï¼"
    exit 1
fi

if [[ -z "$GPU_NUM" ]]; then
    echo "âŒ é”™è¯¯: å¿…é¡»ä¼ å…¥ --gpu-num å‚æ•°ï¼"
    exit 1
fi

# å¦‚æœæœªæŒ‡å®š model-nameï¼Œåˆ™è‡ªåŠ¨å–è·¯å¾„æœ€åä¸€çº§ç›®å½•å
if [[ -z "$MODEL_NAME" ]]; then
    MODEL_NAME=$(basename "${MODEL_PATH%/}")
    echo "â„¹ï¸ æœªæŒ‡å®š --model-nameï¼Œè‡ªåŠ¨ä½¿ç”¨æ¨¡å‹å: $MODEL_NAME"
fi

# ---- å®šä¹‰æµ‹è¯•ç»„åˆ ----

# ---- åˆ›å»ºæ—¥å¿—ç›®å½• ----
# LOG_DIR="./vllm_bench_logs/${MODEL_NAME}_$(date +%Y%m%d_%H%M%S)"
LOG_DIR="./vllm_bench_logs/${MODEL_NAME}_tp${GPU_NUM}_dtype${DTYPE}_$(date +%Y%m%d_%H%M%S)"
CLIENT_LOG_DIR="$LOG_DIR/client_log"
mkdir -p "$CLIENT_LOG_DIR"

echo "============================================"
echo "ğŸš€ å¯åŠ¨ vLLM æ‰¹é‡æ€§èƒ½æµ‹è¯•"
echo "Model Path:  $MODEL_PATH"
echo "Model Name:  $MODEL_NAME"
echo "Host:        $HOST"
echo "Port:        $PORT"
echo "æ—¥å¿—è¾“å‡ºç›®å½•: $LOG_DIR"
echo "============================================"

# ---- è¯»å–é…ç½®æ–‡ä»¶ ----
while read -r line || [[ -n "$line" ]]; do
    # è·³è¿‡æ³¨é‡Šæˆ–ç©ºè¡Œ
    [[ -z "$line" || "$line" =~ ^# ]] && continue

    # è¯»å–å¹¶å‘æ•°ã€è¾“å…¥é•¿åº¦ã€è¾“å‡ºé•¿åº¦
    IFS=' ' read -r CONC INPUT_LEN OUTPUT_LEN <<< "$line"

    echo "â–¶ï¸è¯·æ±‚æ•°: ${CONC}, å¹¶å‘: ${CONC}, è¾“å…¥: ${INPUT_LEN}, è¾“å‡º: ${OUTPUT_LEN}"
    LOG_FILE=$LOG_DIR/${MODEL_NAME}_vllm_result.json
    GPU_LOG_DIR="${LOG_DIR}/gpu_utilization_c${CONC}_in${INPUT_LEN}_out${OUTPUT_LEN}"

    # GPU ç›‘æ§å¯åŠ¨
    python ../../gpu-monitor/mt-gmi-utilization.py \
      --gpu-num "${GPU_NUM}" \
      --interval 2 \
      --gpu-utilization-threshold 10.0 \
      --log-path "$GPU_LOG_DIR" \
      --metadata "model_name=${MODEL_NAME} concurrency=${CONC} input_len=${INPUT_LEN} output_len=${OUTPUT_LEN}" &

    GPU_MONITOR_PID=$!
    echo "âš™ GPU ç›‘æ§å¯åŠ¨, PID=$GPU_MONITOR_PID"
    
    # é…ç½® vLLM bench log å‚æ•°
    VLLM_BENCH_LOG_ARGS="--save-result \
            --append-result \
            --result-filename ${LOG_FILE} \
            --metadata model_name=${MODEL_NAME} concurrency=${CONC} input_len=${INPUT_LEN} output_len=${OUTPUT_LEN}"
            
    bash vllm_bench.sh \
      --model-path "$MODEL_PATH" \
      --model-name "$MODEL_NAME" \
      --host "$HOST" \
      --port "$PORT" \
      --max-concurrency "$CONC" \
      --num-prompts "$CONC" \
      --input-len "$INPUT_LEN" \
      --output-len "$OUTPUT_LEN" \
      --dataset "$DATASET_NAME" \
      --extra $VLLM_BENCH_LOG_ARGS >> ${CLIENT_LOG_DIR}/c"$CONC"_i"$INPUT_LEN"_o"$OUTPUT_LEN".log 2>&1

    # ç»ˆæ­¢ GPU ç›‘æ§
    kill "$GPU_MONITOR_PID"
    wait "$GPU_MONITOR_PID" 2>/dev/null

    python merge_gpu_to_json.py \
      --json "$LOG_FILE" \
      --gpu-log ${GPU_LOG_DIR}/result.log 
    echo "added gpu utilization to ${LOG_FILE}"


    echo "âœ… å·²å®Œæˆ: å¹¶å‘=${CONC}, è¾“å…¥=${INPUT_LEN}, è¾“å‡º=${OUTPUT_LEN}"
    echo "   æ—¥å¿—: $LOG_FILE"
    echo "--------------------------------------------"

    echo "â³ ç­‰å¾…ç³»ç»Ÿç¨³å®š(60s)..."
    sleep 60  # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®š

done < "$CONFIG_FILE"

echo "ğŸ¯ æ‰€æœ‰æ‰¹é‡æµ‹è¯•å·²å®Œæˆï¼ç»“æœæ—¥å¿—ä¿å­˜åœ¨: $LOG_DIR"

