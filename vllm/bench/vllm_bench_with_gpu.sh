#!/usr/bin/env bash
# ==========================================
# vLLM æ‰¹é‡æ€§èƒ½æµ‹è¯•è„šæœ¬
# ä½œè€…: kang.wang-ext
# ==========================================

set -e

show_help() {
cat << EOF
ç”¨æ³•ï¼š
  bash $0 [å‚æ•°...]

å‚æ•°åˆ—è¡¨ï¼š
  --model-path PATH        ï¼ˆå¿…å¡«ï¼‰æ¨¡å‹è·¯å¾„
  --gpu-num N              ï¼ˆå¿…å¡«ï¼‰æ¨ç†ç”¨ GPU æ•°é‡ï¼Œç”¨äºç”Ÿæˆæ—¥å¿—ç›®å½•ä»¥åŠ GPU util ç›‘æ§
  --model-name NAME         (å¯é€‰) æ¨¡å‹æœåŠ¡åï¼Œç¼ºçœåˆ™è‡ªåŠ¨ä»è·¯å¾„æ¨æ–­ï¼ˆä¸åšå¤§å°å†™è½¬æ¢ï¼‰
  --dtype xxx               (å¯é€‰) æ¨ç†ç²¾åº¦ï¼Œä»…ç”¨äºç”Ÿæˆæ—¥å¿—æ ‡è®°
  --port PORT               (å¯é€‰) é»˜è®¤: 8000
  --host HOST               (å¯é€‰) é»˜è®¤: localhost
  --threshold THRESHOLD     (å¯é€‰) ç›‘æ§é˜ˆå€¼ï¼Œæ ¼å¼: "ttft:100 tpot:50", å•ä½ ms, å…è®¸çš„æŒ‡æ ‡: ttft, tpot, e2el
  --help, -h                æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
ç¤ºä¾‹ï¼š
  bash $0 \\
    --model-path /home/dist/DeepSeek-Coder-V2-Lite-Instruct \\
    --model-name DeepSeek-Coder-V2-Lite-Instruct  \\
    --gpu-num 4 \\
    --dtype bf16

  1. 72 ~ 100 è¡Œå¯é…ç½®æµ‹è¯•å¹¶å‘æ•°ä»¥åŠè¾“å…¥è¾“å‡ºç»„åˆï¼
  2. è‡ªåŠ¨ç›‘æ§ GPU åˆ©ç”¨ç‡å¹¶åˆå¹¶è‡³ç»“æœ JSON ä¸­ã€‚
EOF
}

cleanup_threshold_monitor() {
  echo ""
  echo "ğŸ§¹ æ­£åœ¨æ¸…ç†åå°ç›‘æ§è¿›ç¨‹..."

  if [[ -n "$MONITOR_PID" ]] && kill -0 "$MONITOR_PID" 2>/dev/null; then
    echo "ğŸ›‘ åœæ­¢ç›‘æ§è¿›ç¨‹ PID=$MONITOR_PID"
    kill "$MONITOR_PID"
    wait "$MONITOR_PID" 2>/dev/null
  fi

  echo "âœ… æ¸…ç†å®Œæˆ"
}
trap cleanup_threshold_monitor EXIT INT TERM

auto_select_with_threshold() {
    # ---- å¯åŠ¨å®æ—¶ç›‘æ§ç¨‹åºï¼ˆåå°ï¼‰----
    if [[ -n "$THRESHOLD" ]]; then
      echo "ğŸ‘€ å¯åŠ¨å®æ—¶ç›‘æ§ç¨‹åºï¼Œé˜ˆå€¼: $THRESHOLD"

      
      python ./utils/auto_batch_selector.py \
        --log-file "$LOG_FILE" \
        --threshold "$THRESHOLD" \
        --signal-file "$best_signal_file" \
        --output "$LOG_DIR/best_results_with_threshold.json" &
      MONITOR_PID=$!
      echo "ğŸ“¡ ç›‘æ§è¿›ç¨‹ PID=$MONITOR_PID"
    fi
}



parse_args() {
    # ---- å‚æ•°è§£æ ----
    while [[ "$#" -gt 0 ]]; do
        case $1 in
            --model-path) MODEL_PATH="$2"; shift ;;
            --model-name) MODEL_NAME="$2"; shift ;;
            --gpu-num) GPU_NUM="$2"; shift ;;
            --port) PORT="$2"; shift ;;
            --host) HOST="$2"; shift ;;
            --threshold) THRESHOLD="$2"; shift ;;
            --dtype) DTYPE="$2"; shift ;;
            --help|-h) show_help; exit 0 ;;
            *) echo "æœªçŸ¥å‚æ•°: $1"; exit 1 ;;
        esac
        shift
    done

    # å¦‚æœæœªæŒ‡å®š model-nameï¼Œåˆ™è‡ªåŠ¨å–è·¯å¾„æœ€åä¸€çº§ç›®å½•å
    if [[ -z "$MODEL_NAME" ]]; then
        MODEL_NAME=$(basename "${MODEL_PATH%/}")
        echo "â„¹ï¸ æœªæŒ‡å®š --model-nameï¼Œè‡ªåŠ¨ä½¿ç”¨æ¨¡å‹å: $MODEL_NAME"
    fi

    # ---- æ ¡éªŒå¿…å¡«é¡¹ ----
    if [[ -z "$MODEL_PATH" ]]; then
        echo "âŒ é”™è¯¯: å¿…é¡»ä¼ å…¥ --model-path å‚æ•°ï¼"
        exit 1
    fi
    if [[ -z "$GPU_NUM" ]]; then
        echo "âŒ é”™è¯¯: å¿…é¡»ä¼ å…¥ --gpu-num å‚æ•°ï¼"
        exit 1
    fi
}
parse_args "$@"

# ---- é»˜è®¤å‚æ•° ----
HOST="localhost"
PORT=8000
DATASET_NAME="random"

# ---- åˆ›å»ºæ—¥å¿—ç›®å½• ----
LOG_DIR="./vllm_bench_logs/${MODEL_NAME}_tp${GPU_NUM}${DTYPE:+_dtype${DTYPE}}_$(date +%Y%m%d_%H%M%S)"
CLIENT_LOG_DIR="$LOG_DIR/client_log"
mkdir -p "$CLIENT_LOG_DIR"


## ---- å®šä¹‰ç»“æœæ—¥å¿—æ–‡ä»¶ ----
best_signal_file="./utils/best_signal.json"
LOG_FILE="$LOG_DIR/${MODEL_NAME}_vllm_result.json"

# ---- å®šä¹‰æµ‹è¯•ç»„åˆ ----
CONCURRENCY_LIST=(1 2 4 8 16 32 64 128)
LENGTH_PAIRS=(
  # å¹³è¡¡åœºæ™¯ï¼ˆ10ç§ï¼‰
  "256 256"
  "512 512"
  "1024 1024"
  "2048 2048"
  "4096 4096"
  "8192 8192"
  "16384 16384"
  "32768 32768"
  "65536 65536"
  "131072 131072"
  # ä¸å¹³è¡¡åœºæ™¯ï¼ˆ7ç§ï¼‰
  # RAGåœºæ™¯ï¼šå¤§è¾“å…¥å°è¾“å‡º
  "2048 1024"
  "4096 1024"

  # å†…å®¹ç”Ÿæˆï¼šå°è¾“å…¥å¤§è¾“å‡º
  "128 2048"

  # å†…å®¹å®¡æŸ¥/ç®€è¦åˆ†æï¼šå¤§è¾“å…¥å°è¾“å‡º
  "2048 128"

  # é•¿å¤æ‚æ¨ç†
  "1024 5000"
  "1024 8192"
  "1024 16384"
)


echo "============================================"
echo "ğŸš€ å¯åŠ¨ vLLM æ‰¹é‡æ€§èƒ½æµ‹è¯•"
echo "Model Path:  $MODEL_PATH"
echo "Model Name:  $MODEL_NAME"
echo "Host:        $HOST"
echo "Port:        $PORT"
echo "æ—¥å¿—è¾“å‡ºç›®å½•: $LOG_DIR"
echo "============================================"

# ---- å¯åŠ¨è‡ªåŠ¨é€‰æ‹©ç›‘æ§ï¼ˆå¦‚æœè®¾ç½®äº†é˜ˆå€¼ï¼‰----
auto_select_with_threshold

TASKS_JSON=$(python ./utils/bench_task_generator.py ./utils/bench.cfg)
TASKS=$(echo "$TASKS_JSON" | jq -c '.[]')  # å•è¡ŒJSONå¯¹è±¡

# ---- æ‰§è¡Œæ‰¹é‡æµ‹è¯• ----
for task in $TASKS; do
    INPUT_LEN=$(echo "$task" | jq -r '.input_len')
    OUTPUT_LEN=$(echo "$task" | jq -r '.output_len')
    CONCURRENCY=$(echo "$task" | jq -r '.concurrency')
    NUM_REQUESTS=$(echo "$task" | jq -r '.num_requests')
    TASK_MODE=$(echo "$task" | jq -r '.task_mode')

    SKIPPED_COMBOS=()
    combo="${INPUT_LEN}_${OUTPUT_LEN}"

    echo "â–¶ï¸ è¯·æ±‚ï¼š$NUM_REQUESTS å¹¶å‘: $CONCURRENCY, è¾“å…¥: $INPUT_LEN, è¾“å‡º: $OUTPUT_LEN"

    GPU_LOG_DIR="${LOG_DIR}/gpu_utilization_c${CONCURRENCY}_in${INPUT_LEN}_out${OUTPUT_LEN}"
    python ../../gpu-monitor/mt-gmi-utilization.py \
      --gpu-num "${GPU_NUM}" \
      --interval 2 \
      --gpu-utilization-threshold 10.0 \
      --log-path "$GPU_LOG_DIR" \
      --metadata "model_name=${MODEL_NAME} concurrency=${CONCURRENCY} input_len=${INPUT_LEN} output_len=${OUTPUT_LEN}" &

    GPU_MONITOR_PID=$!
    echo "âš™ GPU ç›‘æ§å¯åŠ¨, PID=$GPU_MONITOR_PID"
    
    VLLM_BENCH_LOG_ARGS="--save-result \
            --append-result \
            --result-filename ${LOG_FILE} \
            --metadata model_name=${MODEL_NAME} concurrency=${CONCURRENCY} input_len=${INPUT_LEN} output_len=${OUTPUT_LEN}"
    bash vllm_bench.sh \
      --model-path "$MODEL_PATH" \
      --model-name "$MODEL_NAME" \
      --host "$HOST" \
      --port "$PORT" \
      --max-concurrency "$CONCURRENCY" \
      --num-prompts "$NUM_REQUESTS" \
      --input-len "$INPUT_LEN" \
      --output-len "$OUTPUT_LEN" \
      --dataset "$DATASET_NAME" \
      --extra $VLLM_BENCH_LOG_ARGS >> ${CLIENT_LOG_DIR}/c"$CONCURRENCY"_i"$INPUT_LEN"_o"$OUTPUT_LEN".log 2>&1

    # ç»ˆæ­¢ GPU ç›‘æ§
    kill "$GPU_MONITOR_PID"
    wait "$GPU_MONITOR_PID" 2>/dev/null

    python merge_gpu_to_json.py \
      --json "$LOG_FILE" \
      --gpu-log ${GPU_LOG_DIR}/result.log 
    echo "added gpu utilization to ${LOG_FILE}"


    echo "âœ… å·²å®Œæˆ: å¹¶å‘=${conc}, è¾“å…¥=${INPUT_LEN}, è¾“å‡º=${OUTPUT_LEN}"
    echo "   æ—¥å¿—: $LOG_FILE"
    echo "--------------------------------------------"

    echo "â³ ç­‰å¾…ç³»ç»Ÿç¨³å®š(60s)..."
    sleep 60  # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®š

    if [[ "$TASK_MODE" == "grid" ]] && [[ -f "$best_signal_file" ]]; then
      SKIPPED_COMBOS+=("$combo")
      rm "$best_signal_file"
      continue
    fi

    # è·³è¿‡å·²æ ‡è®°ç»„åˆ
    if [[ " ${SKIPPED_COMBOS[@]} " =~ " ${combo} " ]]; then
        continue
    fi

done

echo "ğŸ¯ æ‰€æœ‰æ‰¹é‡æµ‹è¯•å·²å®Œæˆï¼ç»“æœæ—¥å¿—ä¿å­˜åœ¨: $LOG_DIR"

