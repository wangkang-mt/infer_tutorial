import argparse
import json
import time
import streamlit as st

from realtime_bench_core import (
    parse_metadata_list,
    read_new_lines,
    process_records,
    build_chart,
    find_best,
)


# ---------------------------
# CLI å‚æ•°è§£æï¼ˆä½¿ç”¨ parse_known_args ä»¥å…¼å®¹ streamlitï¼‰
# ---------------------------
parser = argparse.ArgumentParser(description="VLLM Real-time Throughput Monitor")
parser.add_argument("--json-file", type=str, required=True, help="Path to json log file")
parser.add_argument(
    "--metadata",
    type=str,
    nargs="*",
    default=[],
    help="Extra metadata like tp=8 dtype=bf16 gpu-mem=0.7",
)
known_args, _ = parser.parse_known_args()

JSON_FILE = known_args.json_file
POLL_INTERVAL = 1

# è§£æ metadata é”®å€¼å¯¹
metadata_dict = parse_metadata_list(known_args.metadata)

# å¦‚æœæœ‰ Streamlit query paramsï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰ï¼Œä» query params è¯»å– metadata
qp = st.query_params
if "metadata" in qp and qp["metadata"]:
    # æ”¯æŒ ?metadata=tp=8&metadata=dtype=bf16
    metadata_dict = parse_metadata_list(qp.get("metadata"))
# æ”¯æŒé€šè¿‡ query params æŒ‡å®š json æ–‡ä»¶ï¼š ?json-file=/path/to/log
if "json-file" in qp and qp["json-file"]:
    JSON_FILE = qp.get("json-file")[0]


# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ğŸ”¥ VLLM å®æ—¶ååç›‘æ§ Dashboard")

# æ˜¾ç¤º metadata
if metadata_dict:
    md_lines = "\n".join([f"- **{k}**: `{v}`" for k, v in metadata_dict.items()])
    st.markdown(f"""
### âš™ï¸ æµ‹è¯•å…ƒä¿¡æ¯ï¼ˆMetadataï¼‰
{md_lines}
""")

# session ä¸­å­˜å‚¨æ‰€æœ‰ JSON
if "records" not in st.session_state:
    st.session_state.records = []

placeholder_chart = st.empty()
placeholder_best = st.empty()
placeholder_model = st.empty()


offset = 0


def main_loop():
    global offset
    while True:
        lines, offset = read_new_lines(JSON_FILE, offset)

        for line in lines:
            line = line.strip()
            if not line:
                continue
            try:
                js = json.loads(line)
                st.session_state.records.append(js)
            except Exception:
                continue

        if not st.session_state.records:
            time.sleep(POLL_INTERVAL)
            continue

        df = process_records(st.session_state.records)

        # æ¨¡å‹å
        if "model_name" in df.columns:
            model_names = df["model_name"].unique()
            placeholder_model.markdown(f"### ğŸ§© å½“å‰æ¨¡å‹ï¼š{' | '.join(model_names)}")

        best = find_best(df)
        if best is not None:
            placeholder_best.markdown(f"""
### ğŸŸ¢ å½“å‰æœ€é«˜ååç»„åˆ
- **æ¨¡å‹**ï¼š`{best['model_name']}`
- **å¹¶å‘**ï¼š`{best['concurrency']}`  
- **è¾“å…¥é•¿åº¦**ï¼š`{best['input_len']}`  
- **è¾“å‡ºé•¿åº¦**ï¼š`{best['output_len']}`  
- **åå**ï¼š`{best['total_token_throughput']:.2f}` token/s  
""")

        chart = build_chart(df)
        placeholder_chart.altair_chart(chart, width="stretch")

        time.sleep(POLL_INTERVAL)


if __name__ == "__main__":
    main_loop()
