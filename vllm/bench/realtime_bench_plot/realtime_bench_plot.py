import argparse
import json
import time
import streamlit as st
import zipfile
import io
from pathlib import Path

from realtime_bench_core import (
    parse_metadata_list,
    read_new_lines,
    process_records,
    build_chart,
    find_best,
)


# ---------------------------
# CLI å‚æ•°è§£æï¼ˆä½¿ç”¨ parse_known_args ä»¥å…¼å®¹ streamlitï¼‰
# ---------------------------
parser = argparse.ArgumentParser(description="VLLM Real-time Throughput Monitor")
parser.add_argument("--json-file", type=str, required=True, help="Path to json log file")
parser.add_argument(
    "--metadata",
    type=str,
    nargs="*",
    default=[],
    help="Extra metadata like tp=8 dtype=bf16 gpu-mem=0.7",
)
known_args, _ = parser.parse_known_args()

JSON_FILE = known_args.json_file
POLL_INTERVAL = 1

# è§£æ metadata é”®å€¼å¯¹
metadata_dict = parse_metadata_list(known_args.metadata)

# å¦‚æœæœ‰ Streamlit query paramsï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰ï¼Œä» query params è¯»å– metadata
qp = st.query_params
if "metadata" in qp and qp["metadata"]:
    # æ”¯æŒ ?metadata=tp=8&metadata=dtype=bf16
    metadata_dict = parse_metadata_list(qp.get("metadata"))
# æ”¯æŒé€šè¿‡ query params æŒ‡å®š json æ–‡ä»¶ï¼š ?json-file=/path/to/log
if "json-file" in qp and qp["json-file"]:
    JSON_FILE = qp.get("json-file")[0]


# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ğŸ”¥ vLLM å®æ—¶ååç›‘æ§ Dashboard")


# ä¾§è¾¹æ ï¼šæ˜¾ç¤ºé…ç½®å’Œä¸‹è½½åŠŸèƒ½
with st.sidebar:
    st.header("âš™ï¸ é…ç½®ä¸å·¥å…·")
    
    # æ˜¾ç¤ºå½“å‰ JSON æ–‡ä»¶è·¯å¾„
    st.markdown(f"**JSON æ–‡ä»¶**: `{JSON_FILE}`")
    
    # ç”Ÿæˆå’Œæä¾›ä¸‹è½½æŒ‰é’®
    try:
        json_path = Path(JSON_FILE).resolve()
        parent_dir = json_path.parent
        
        # åˆ›å»º ZIP æ–‡ä»¶ï¼ˆå†…å­˜ä¸­ï¼‰
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in parent_dir.rglob("*"):
                if file_path.is_file():
                    arcname = file_path.relative_to(parent_dir.parent)
                    zip_file.write(file_path, arcname=arcname)
        
        zip_buffer.seek(0)
        
        # æä¾›ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ“¦ ä¸‹è½½ç›®å½•ï¼ˆZIPï¼‰",
            data=zip_buffer.getvalue(),
            file_name=f"{parent_dir.name}.zip",
            mime="application/zip",
            key="download_dir"
        )
        st.success(f"âœ… å·²å‡†å¤‡å¥½ä¸‹è½½ `{parent_dir.name}/` ç›®å½•")
    except Exception as e:
        st.error(f"âŒ æ— æ³•ç”Ÿæˆä¸‹è½½æ–‡ä»¶: {str(e)}")

# æ˜¾ç¤º metadata
if metadata_dict:
    md_lines = "\n".join([f"- **{k}**: `{v}`" for k, v in metadata_dict.items()])
    st.markdown(f"""
### âš™ï¸ æµ‹è¯•å…ƒä¿¡æ¯ï¼ˆMetadataï¼‰
{md_lines}
""")

# session ä¸­å­˜å‚¨æ‰€æœ‰ JSON
if "records" not in st.session_state:
    st.session_state.records = []

placeholder_chart = st.empty()
placeholder_best = st.empty()
placeholder_model = st.empty()


offset = 0


def main_loop():
    global offset
    while True:
        lines, offset = read_new_lines(JSON_FILE, offset)

        for line in lines:
            line = line.strip()
            if not line:
                continue
            try:
                js = json.loads(line)
                st.session_state.records.append(js)
            except Exception:
                continue

        if not st.session_state.records:
            time.sleep(POLL_INTERVAL)
            continue

        df = process_records(st.session_state.records)

        # æ¨¡å‹å
        if "model_name" in df.columns:
            model_names = df["model_name"].unique()
            placeholder_model.markdown(f"### ğŸ§© å½“å‰æ¨¡å‹ï¼š{' | '.join(model_names)}")

        best = find_best(df)
        if best is not None:
            placeholder_best.markdown(f"""
### ğŸŸ¢ å½“å‰æœ€é«˜ååç»„åˆ
- **æ¨¡å‹**ï¼š`{best['model_name']}`
- **å¹¶å‘**ï¼š`{best['concurrency']}`  
- **è¾“å…¥é•¿åº¦**ï¼š`{best['input_len']}`  
- **è¾“å‡ºé•¿åº¦**ï¼š`{best['output_len']}`  
- **åå**ï¼š`{best['total_token_throughput']:.2f}` token/s  
""")

        chart = build_chart(df)
        placeholder_chart.altair_chart(chart, width="stretch")

        time.sleep(POLL_INTERVAL)


if __name__ == "__main__":
    main_loop()
