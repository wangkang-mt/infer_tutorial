#!/bin/bash

#########################################
# vLLM Serve å¯åŠ¨è„šæœ¬
# å¯ä¼ å‚ï¼š
#   --model-path
#   --served-model-name
#   --dtype
#   --max-model-len
#   --tp / --tensor-parallel
#   --pp / --pipeline-parallel
#   --gpu-mem
#
# ç”¨æ³•ç¤ºä¾‹ï¼š
# bash start_vllm.sh \
#   --model-path /data/models/DeepSeek-R1-Distill-Qwen-32B \
#   --served-model-name DeepSeek-R1-Distill-Qwen-32B \
#   --dtype bfloat16 \
#   --tp 8 \
#   --max-model-len 32768 \
#   --gpu-mem 0.7
#########################################

show_help() {
cat << EOF
ç”¨æ³•ï¼š
  bash $0 [å‚æ•°...]

å‚æ•°åˆ—è¡¨ï¼š
  --model-path PATH            ï¼ˆå¿…å¡«ï¼‰æ¨¡å‹è·¯å¾„
  --served-model-name NAME     æœåŠ¡æ¨¡å‹åï¼ˆé»˜è®¤è‡ªåŠ¨ä»è·¯å¾„æ¨æ–­ï¼‰
  --dtype DTYPE                é»˜è®¤: bfloat16
  --max-model-len N            æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
  --tp, --tensor-parallel N    é»˜è®¤: 8
  --pp, --pipeline-parallel N  é»˜è®¤: 1(ä¸å¯æ›´æ”¹)
  --gpu-mem FLOAT              GPU å†…å­˜åˆ©ç”¨ç‡(é»˜è®¤ 0.7)
  --host HOST                  é»˜è®¤ 0.0.0.0
  --port PORT                  é»˜è®¤ 8000
  --save-logs LOG_PATH             æ—¥å¿—ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤ä¿å­˜å½“å‰ç›®å½•ï¼‰

ç¤ºä¾‹ï¼š
  bash $0 \\
    --model-path /data/models/DeepSeek-R1-Distill-Qwen-32B \\
    --dtype bfloat16 \\
    --tp 8 \\
    --max-model-len 32768

EOF
}

# é»˜è®¤å‚æ•°
MODEL_PATH=""
MODEL_NAME=""
DTYPE="bfloat16"
TP=8
PP=1
GPU_MEM=0.7
PORT=8000
HOST="0.0.0.0"

# LOG 
LOG_FILE=""
LOG_DIR="./vllm_serve_logs"

EXTRA_ARGS=()

# è§£æå‚æ•°
while [[ $# -gt 0 ]]; do
  case $1 in
      -h|--help)
      show_help
      exit 0
      ;;
    --model-path)
      MODEL_PATH="$2"
      shift 2
      ;;
    --served-model-name|--model-name)
      MODEL_NAME="$2"
      shift 2
      ;;
    --dtype)
      DTYPE="$2"
      shift 2
      ;;
    --max-model-len)
      MAX_LEN="$2"
      shift 2
      ;;
    --tp|--tensor-parallel)
      TP="$2"
      shift 2
      ;;
    --pp|--pipeline-parallel)
      PP="$2"
      shift 2
      ;;
    --gpu-mem)
      GPU_MEM="$2"
      shift 2
      ;;
    --port)
      PORT="$2"
      shift 2
      ;;
    --host)
      HOST="$2"
      shift 2
      ;;
    --save-logs)
      LOG_FILE="$2"
      shift 2
      ;;
    *)
      EXTRA_ARGS+=("$1")
      shift
      ;;
  esac
done

# å‚æ•°æ£€æŸ¥
if [[ -z "$MODEL_PATH" ]]; then
  echo "âŒ å¿…é¡»æä¾› --model-path"
  exit 1
fi

# è‡ªåŠ¨æ¨æ–­æ¨¡å‹å
if [[ -z "$MODEL_NAME" ]]; then
  MODEL_NAME=$(basename "$MODEL_PATH")
  # å»æ‰è·¯å¾„æœ«å°¾çš„ "/"ï¼ˆå¦‚æœæœ‰ï¼‰
  MODEL_NAME=${MODEL_NAME%/}
  echo "âš ï¸ æœªæŒ‡å®š --served-model-name, è‡ªåŠ¨æ¨æ–­ä¸º: $MODEL_NAME"
fi

if [[ -z "$LOG_FILE" ]]; then
    LOG_FILE="${LOG_DIR}/vllm_serve_${MODEL_NAME}_tp${TP}_pp${PP}_dtype${DTYPE}.log"
    mkdir -p "$LOG_DIR"
fi

echo "========================================"
echo "ğŸš€ å¯åŠ¨ vLLM æ¨ç†æœåŠ¡..."
echo " Model Path:         $MODEL_PATH"
echo " Served Model Name:  $MODEL_NAME"
echo " DType:              $DTYPE"
echo " Max Model Len:      ${MAX_LEN:-'(æœªè®¾ç½®)'}"
echo " TP:                 $TP"
echo " PP:                 $PP"
echo " GPU Mem Util:       $GPU_MEM"
echo " Host:               $HOST"
echo " Port:               $PORT"
echo "========================================"

# å¯åŠ¨å‘½ä»¤

CMD=(
  vllm serve
  "$MODEL_PATH"
  --trust-remote-code
  --served-model-name "$MODEL_NAME"
  --gpu-memory-utilization "$GPU_MEM"
  --block-size 64
  --dtype "$DTYPE"
  --tensor-parallel-size "$TP"
  --pipeline-parallel-size "$PP"
  --host "$HOST"
  --port "$PORT"
  "${EXTRA_ARGS[@]}"
)


[[ -n "$MAX_LEN" ]] && CMD+=(--max-model-len "$MAX_LEN")

COMPILATION_CONFIG='{"cudagraph_capture_sizes":[1,2,3,4,5,6,7,8,10,12,14,16,18,20,24,28,30], "simple_cuda_graph": true}'
CMD+=(--compilation-config "$COMPILATION_CONFIG")


echo ""
echo "ğŸš€ å¯åŠ¨å‘½ä»¤ï¼š"
printf "%s " "${CMD[@]}"
echo ""
echo ""

# æ‰§è¡Œ
# exec "${CMD[@]}" >> "$LOG_FILE" 2>&1
echo "ğŸ’¾ æ—¥å¿—: $LOG_FILE"