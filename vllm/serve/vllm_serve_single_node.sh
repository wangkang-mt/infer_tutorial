#!/bin/bash

#########################################
# vLLM Serve å¯åŠ¨è„šæœ¬
# å¯ä¼ å‚ï¼š
#   --model-path
#   --served-model-name
#   --dtype
#   --max-model-len
#   --tp / --tensor-parallel
#   --pp / --pipeline-parallel
#   --gpu-mem
#
# ç”¨æ³•ç¤ºä¾‹ï¼š
# bash start_vllm.sh \
#   --model-path /data/models/DeepSeek-R1-Distill-Qwen-32B \
#   --served-model-name DeepSeek-R1-Distill-Qwen-32B \
#   --dtype bfloat16 \
#   --tp 8 \
#   --max-model-len 32768 \
#   --gpu-mem 0.7
#########################################

show_help() {
cat << EOF
ç”¨æ³•ï¼š
  bash $0 [å‚æ•°...]

å‚æ•°åˆ—è¡¨ï¼š

  vllm serve å¯åŠ¨å‚æ•°ï¼š
    --model-path PATH            ï¼ˆå¿…å¡«ï¼‰æ¨¡å‹è·¯å¾„
    --served-model-name NAME     ï¼ˆå¯é€‰ï¼‰æœåŠ¡æ¨¡å‹åï¼ˆé»˜è®¤è‡ªåŠ¨ä»è·¯å¾„æ¨æ–­ï¼‰
    --dtype DTYPE                ï¼ˆå¯é€‰ï¼‰é»˜è®¤: bfloat16
    --max-model-len N            ï¼ˆå¯é€‰ï¼‰æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
    --tp, --tensor-parallel N    ï¼ˆå¯é€‰ï¼‰é»˜è®¤: 1
    --pp, --pipeline-parallel N  ï¼ˆå¯é€‰ï¼‰é»˜è®¤: 1 (æ¨èä¸åšæ›´æ”¹)
    --gpu-mem FLOAT              ï¼ˆå¯é€‰ï¼‰GPU å†…å­˜åˆ©ç”¨ç‡(é»˜è®¤ 0.9)
    --host HOST                  ï¼ˆå¯é€‰ï¼‰é»˜è®¤ 0.0.0.0
    --port PORT                  ï¼ˆå¯é€‰ï¼‰é»˜è®¤ 8000

    è¯´æ˜ï¼š
    1. ä¸ºæ–¹ä¾¿ bench æµ‹è¯•ï¼Œè„šæœ¬é»˜è®¤é…ç½®å‚æ•° --eager-eos;
    2. é»˜è®¤å¼€å¯ cuda graph ä¼˜åŒ–ï¼Œé€‚ç”¨äºå¤§å¤šæ•°æ¨¡å‹;

  æ—¥å¿—å‚æ•°ï¼š
    --log-dir LOG_DIR         æ—¥å¿—ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤ä¿å­˜åœ¨./vllm_serve_logsï¼‰

  otherï¼š
    å¯é€šè¿‡åœ¨å‘½ä»¤è¡Œæœ«å°¾æ·»åŠ é¢å¤–å‚æ•°å®ç°ï¼Œè¯¦è§ vllm serve æ–‡æ¡£ã€‚

ç¤ºä¾‹ï¼š
  # åŸºç¡€å¯åŠ¨
  bash $0 \\
    --model-path /data/models/DeepSeek-R1-Distill-Qwen-32B \\
    --dtype bfloat16 \\
    --tp 8 \\
    --max-model-len 32768

  # é¢å¤–å‚æ•°ç¤ºä¾‹
  bash $0 \\
    --model-path /data/models/DeepSeek-R1-Distill-Qwen-32B \\
    --dtype bfloat16 \\
    --tp 8 \\
    --max-model-len 32768
    --max-num-batched-tokens 32768 \
    --max-seq-len-to-capture 32768 \
    --no-enable-prefix-caching 
EOF
}

# é»˜è®¤å‚æ•°
MODEL_PATH=""
MODEL_NAME=""
DTYPE="bfloat16"
TP=1
PP=1
GPU_MEM=0.9
PORT=8000
HOST="0.0.0.0"

# LOG 
LOG_FILE=""    # è‡ªåŠ¨åŸºäº LOG_DIR ç”Ÿæˆ
LOG_DIR="./vllm_serve_logs"

EXTRA_ARGS=()

# è§£æå‚æ•°
while [[ $# -gt 0 ]]; do
  case $1 in
      -h|--help)
      show_help
      exit 0
      ;;
    --model-path)
      MODEL_PATH="$2"
      shift 2
      ;;
    --served-model-name|--model-name)
      MODEL_NAME="$2"
      shift 2
      ;;
    --dtype)
      DTYPE="$2"
      shift 2
      ;;
    --max-model-len)
      MAX_LEN="$2"
      shift 2
      ;;
    --tp|--tensor-parallel)
      TP="$2"
      shift 2
      ;;
    --pp|--pipeline-parallel)
      PP="$2"
      shift 2
      ;;
    --gpu-mem)
      GPU_MEM="$2"
      shift 2
      ;;
    --port)
      PORT="$2"
      shift 2
      ;;
    --host)
      HOST="$2"
      shift 2
      ;;
    --log-dir)
      LOG_DIR="$2"
      shift 2
      ;;
    *)
      EXTRA_ARGS+=("$1")
      shift
      ;;
  esac
done

# å‚æ•°æ£€æŸ¥
if [[ -z "$MODEL_PATH" ]]; then
  echo "âŒ å¿…é¡»æä¾› --model-path"
  exit 1
fi

# è‡ªåŠ¨æ¨æ–­æ¨¡å‹å
if [[ -z "$MODEL_NAME" ]]; then
  MODEL_NAME=$(basename "$MODEL_PATH")
  # å»æ‰è·¯å¾„æœ«å°¾çš„ "/"ï¼ˆå¦‚æœæœ‰ï¼‰
  MODEL_NAME=${MODEL_NAME%/}
  echo "âš ï¸ æœªæŒ‡å®š --served-model-name, è‡ªåŠ¨æ¨æ–­ä¸º: $MODEL_NAME"
fi

# è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
if [[ -n "$LOG_DIR" ]]; then
    LOG_FILE="${LOG_DIR}/vllm_serve_${MODEL_NAME}_tp${TP}_pp${PP}_dtype${DTYPE}.log"
    mkdir -p "$LOG_DIR"
fi

echo "========================================"
echo "ğŸš€ å¯åŠ¨ vLLM æ¨ç†æœåŠ¡..."
echo " Model Path:         $MODEL_PATH"
echo " Served Model Name:  $MODEL_NAME"
echo " DType:              $DTYPE"
echo " Max Model Len:      ${MAX_LEN:-'(None)'}"
echo " Max Concurrency:    ${MAX_CONCURRENCY:-'(None)'}"
echo " TP:                 $TP"
echo " PP:                 $PP"
echo " GPU Mem Util:       $GPU_MEM"
echo " Host:               $HOST"
echo " Port:               $PORT"

echo " Log File:          $LOG_FILE"
echo "========================================"


# å¯åŠ¨å‘½ä»¤

CMD=(
  vllm serve
  "$MODEL_PATH"
  --trust-remote-code
  --served-model-name "$MODEL_NAME"
  --gpu-memory-utilization "$GPU_MEM"
  --block-size 64
  --dtype "$DTYPE"
  --tensor-parallel-size "$TP"
  --pipeline-parallel-size "$PP"
  --eager-eos
  --host "$HOST"
  --port "$PORT"
  "${EXTRA_ARGS[@]}"
)


[[ -n "$MAX_LEN" ]] && CMD+=(--max-model-len "$MAX_LEN")

COMPILATION_CONFIG='{"cudagraph_capture_sizes":[1,2,3,4,5,6,7,8,10,12,14,16,18,20,24,28,30,32,50,64,100,128,256], "simple_cuda_graph": true}'
CMD+=(--compilation-config "$COMPILATION_CONFIG")


echo ""
echo "ğŸš€ å¯åŠ¨å‘½ä»¤ï¼š"
printf "%s " "${CMD[@]}"
echo ""
echo ""

# æ‰§è¡Œ
exec "${CMD[@]}" >> "$LOG_FILE" 2>&1
echo "ğŸ’¾ æ—¥å¿—: $LOG_FILE"